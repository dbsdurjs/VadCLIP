# 16ê°œ í´ë˜ìŠ¤ ì¤‘ ì´ì „ 8ê°œ í´ë˜ìŠ¤ ì‘ì—…
import os
import torch
import multiprocessing
from torch.utils.data import Dataset, DataLoader
from PIL import Image
from transformers import AutoProcessor, AutoModelForImageTextToText
from tqdm import tqdm

# âœ… CPU ì½”ì–´ ê°œìˆ˜ í™•ì¸ í›„ ì ì ˆí•œ num_workers ì„¤ì •
NUM_WORKERS = 8  # ì˜ˆì‹œë¡œ 8ê°œ ì‚¬ìš©
print(f"ğŸ”¹ Using num_workers={NUM_WORKERS}")

# ğŸ“Œ 3. ëª¨ë¸ ë° processor ë¡œë“œ (ë¨¼ì € ë¡œë“œí•˜ì—¬ ë°ì´í„°ì…‹ì— ì „ë‹¬)
processor = AutoProcessor.from_pretrained("Salesforce/blip2-opt-6.7b")
model = AutoModelForImageTextToText.from_pretrained("Salesforce/blip2-opt-6.7b", torch_dtype=torch.float16)

device = "cuda" if torch.cuda.is_available() else "cpu"
model.to(device)

# ğŸ“Œ 1. ê°œë³„ í”„ë ˆì„ì„ ë¡œë”©í•˜ëŠ” ë°ì´í„°ì…‹ (processorë¥¼ í†µí•œ ì „ì²˜ë¦¬ ì ìš©)
class FrameDataset(Dataset):
    def __init__(self, base_folder, processor):
        self.data = []
        self.video_names = []
        self.processor = processor  # processorë¥¼ ë©¤ë²„ ë³€ìˆ˜ë¡œ ì €ì¥

        classes_names = os.listdir(base_folder)
        classes_names = classes_names[8:][3]   # 8ê°œ ì¤‘ ì´ì „ 4ê°œë§Œ
        print(f'ì‘ì—… í´ë” ì´ë¦„ : {classes_names}')

        for class_name in os.listdir(base_folder):

            if class_name not in classes_names:
                continue
            
            class_path = os.path.join(base_folder, class_name)
            if not os.path.isdir(class_path):
                continue

            # í´ë˜ìŠ¤ í´ë” ë‚´ë¶€ì˜ ëª¨ë“  ë™ì˜ìƒ í´ë” ê°€ì ¸ì˜¤ê¸°
            video_folders = sorted(os.listdir(class_path))
            for video_folder in video_folders:
                video_folder_path = os.path.join(class_path, video_folder)
                if not os.path.isdir(video_folder_path):
                    continue

                # ì„ íƒëœ ë™ì˜ìƒ í´ë”ì˜ í”„ë ˆì„ íŒŒì¼ ë¦¬ìŠ¤íŠ¸
                image_files = sorted([
                    os.path.join(video_folder_path, f) for f in os.listdir(video_folder_path)
                    if f.lower().endswith('.jpg')
                ])
                
                for img in image_files:
                    self.data.append((video_folder_path, img))
                    self.video_names.append(video_folder)

    def __len__(self):
        return len(self.data)

    def __getitem__(self, index):
        video_folder_path, image_path = self.data[index]
        video_name = self.video_names[index]

        # ì´ë¯¸ì§€ ë¡œë“œ ë° RGB ë³€í™˜
        image = Image.open(image_path).convert("RGB")
        # processorë¥¼ ì‚¬ìš©í•˜ì—¬ ì „ì²˜ë¦¬: ë‚´ë¶€ì ìœ¼ë¡œ ë¦¬ì‚¬ì´ì¦ˆ, ì •ê·œí™” ë“± ì ìš©ë¨
        inputs = self.processor(images=image, return_tensors="pt")
        # inputs['pixel_values']ì˜ shapeëŠ” [1, C, H, W]ì´ë¯€ë¡œ squeezeë¡œ ë°°ì¹˜ ì°¨ì› ì œê±°
        pixel_values = inputs["pixel_values"].squeeze(0)
        
        return video_folder_path, image_path, pixel_values, video_name

# ğŸ“Œ 2. ë°ì´í„°ì…‹ ë° ë°ì´í„° ë¡œë” ìƒì„±
base_folder = "/media/vcl/DATA/YG/Extracted_Frames/"
dataset = FrameDataset(base_folder, processor)
dataloader = DataLoader(dataset, batch_size=128, shuffle=False, num_workers=NUM_WORKERS, pin_memory=False)

# ğŸ“Œ 4. ë°°ì¹˜ ë‹¨ìœ„ë¡œ ìº¡ì…˜ ìƒì„± (ë¹„ë””ì˜¤ëª… í¬í•¨)
def generate_captions(dataloader, model, processor, device):
    model.eval()
    current_video = None

    with torch.no_grad():
        progress_bar = tqdm(dataloader, desc="Processing Videos", unit="batch", dynamic_ncols=True)

        for batch in progress_bar:
            video_folder_paths, image_paths, pixel_values, video_names = batch

            if current_video is None or current_video != video_names[0]:
                current_video = video_names[0]
                print(f"\nğŸ¥ Processing video: {current_video}")

            pixel_values = pixel_values.to(device, torch.float16)

            generated_ids = model.generate(pixel_values=pixel_values, max_length=50)
            captions = processor.tokenizer.batch_decode(generated_ids, skip_special_tokens=True)

            for video_folder_path, image_path, caption in zip(video_folder_paths, image_paths, captions):
                frame_number = os.path.basename(image_path)
                output_file = os.path.join(video_folder_path, f"{os.path.basename(video_folder_path)}.txt")

                with open(output_file, "a", encoding="utf-8") as f:
                    f.write(f"{frame_number}: {caption}")

                # print(f'ğŸ–¼ï¸ Frame: {frame_number} | ğŸ“œ Caption: {caption}')

            progress_bar.set_postfix({"Current Video": current_video, "Processed Frames": len(pixel_values)})

        print("\nâœ… All videos processed successfully!")

# ğŸ“Œ 4. ê¸°ì¡´ íŒŒì¼ ì‚­ì œ (ì´ì „ ê²°ê³¼ ì§€ìš°ê¸°)
def delete_existing_files(base_folder):
    
    classes_names = os.listdir(base_folder)[8:][3] # 8ê°œ ì¤‘ ì´ì „ 4ê°œë§Œ
    print(f"ì‚­ì œí•  ì‘ì—… í´ë”: {classes_names}")
    
    for class_name in classes_names:
        class_path = os.path.join(base_folder, class_name)
        if not os.path.isdir(class_path):
            continue
        
        for video_folder in os.listdir(class_path):
            video_folder_path = os.path.join(class_path, video_folder)
            if not os.path.isdir(video_folder_path):
                continue
            
            output_file = os.path.join(video_folder_path, f"{video_folder}.txt")
            if os.path.exists(output_file):
                os.remove(output_file)
                print(f"ğŸ—‘ï¸ Deleted existing file: {output_file}")

if __name__ == '__main__':

    # ğŸ“Œ 5. ìº¡ì…˜ ìƒì„± ì‹¤í–‰
    delete_existing_files(base_folder)
    generate_captions(dataloader, model, processor, device)
